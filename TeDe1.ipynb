{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QTLHOSDRlAGO"
   },
   "source": [
    "sdi2100007 - Μιχαήλ Αρετάκης <br>\n",
    "sdi2100222 - Γεώργιος Παπαϊωάννου"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "executionInfo": {
     "elapsed": 5806,
     "status": "error",
     "timestamp": 1755178525995,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "3_wMq0f28CuO",
    "outputId": "1e726d15-6171-4c3e-d28d-57c1ad3f5f5f"
   },
   "outputs": [
    {
     "ename": "MessageError",
     "evalue": "Error: credential propagation was unsuccessful",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEX-tz0d7oge"
   },
   "source": [
    "Στο παραπάνω κελί, κάνουμε mount το Google Drive μας, που περιέχει τα δεδομένα που απαιτούνται για το project. Χρησιμοποιούμε ενα relative path για την πρόσβαση στα δεδομένα \"/content/drive/MyDrive/data/...\"\n",
    "\n",
    "Στο παρακάτω κελί, ο κώδικας συγκεντρώνει τα δεδομένα στα ζητούμενα αρχεία train_2019/2023.csv\n",
    "\n",
    "**Παρατήρηση:** Παίρνουμε τη στήλη neighbourhood_cleansed, διότι οι γειτονίες είναι πιο καθαρογραμμένες και κάνει την ομαδοποίηση των δεδομένων πιο εύκολη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "aborted",
     "timestamp": 1755178526054,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "RojYNEcbqLVT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "\n",
    "wantedColumns = ['id', 'zipcode', 'transit', 'bedrooms', 'beds',\n",
    "                'review_scores_rating', 'number_of_reviews',\n",
    "                'neighbourhood_cleansed', 'name', 'latitude', 'longitude',\n",
    "                'last_review', 'instant_bookable', 'host_since',\n",
    "                'host_response_rate', 'host_identity_verified',\n",
    "                'host_has_profile_pic', 'first_review', 'description',\n",
    "                'city', 'cancellation_policy', 'bed_type', 'bathrooms',\n",
    "                'accommodates', 'amenities', 'room_type', 'property_type',\n",
    "                'price', 'availability_365', 'minimum_nights', 'host_id']\n",
    "\n",
    "data = {\n",
    "    '2019': ['febrouary', 'march', 'april'],\n",
    "    '2023': ['march', 'june', 'september']\n",
    "}\n",
    "data_2019 = []\n",
    "data_2023 = []\n",
    "\n",
    "for year, months in data.items():\n",
    "  for month in months:\n",
    "    file_path = f'/content/drive/MyDrive/data/{year}/{month}/listings.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    df = df.filter(wantedColumns)\n",
    "    df = df.rename(columns={'neighbourhood_cleansed':'neighbourhood'})\n",
    "    df['Month'] = month\n",
    "    if year == '2019':\n",
    "      data_2019.append(df)\n",
    "    else:\n",
    "      data_2023.append(df)\n",
    "\n",
    "combined_data_2019 = pd.concat(data_2019)\n",
    "combined_data_2023 = pd.concat(data_2023)\n",
    "combined_data_2023\n",
    "combined_data_2019.to_csv('/content/drive/MyDrive/data/2019/train_2019.csv')\n",
    "combined_data_2023.to_csv('/content/drive/MyDrive/data/2023/train_2023.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tLi856SX9uJN"
   },
   "source": [
    "* Τώρα φιλτράρουμε τις τιμές NaN συμπληρώνοντας τις αριθμητικές στήλες με τη μέση τιμή της στήλης, σημειώνοντας τις εξαιρέσεις όπου ολόκληρες στήλες είναι κενές. Για τις στήλες συμβολοσειρών, τις αντικαθιστούμε με άγνωστο.\n",
    "\n",
    "* Για υπερβολικές τιμές, αναλύσαμε κάθε στήλη αποφασίσαμε ότι:\n",
    "\n",
    "  Οι τιμές για τις περισσότερες αριθμητικές στήλες ήταν ρεαλιστικές και επομένως δεν χρειάζονταν επιπλέον φιλτράρισμα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6048,
     "status": "aborted",
     "timestamp": 1755178526056,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "3pOI2xk39udE"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "dfs = {}  # USE AN ARRAY TO STORE THE DFS OF EACH YEAR SEPARATELY FOR FUTURE PROCESSING\n",
    "years = ['2019','2023']\n",
    "for year in years:\n",
    "  file_path = f'/content/drive/MyDrive/data/{year}/train_{year}.csv'\n",
    "  df = pd.read_csv(file_path)\n",
    "\n",
    "  for col in df.select_dtypes(include=np.number).columns:\n",
    "    if df[col].isna().all(): # CHECK IF THE ENTIRE COLUMN IS NAN\n",
    "      df[col].fillna(0, inplace=True)  # FILL WITH 0 WHERE THE ENTIRE COLUMN IS NAN (2023 bathrooms)\n",
    "    else:\n",
    "      df[col].fillna(df[col].mean(), inplace=True) # FILL NAN VALUES WITH THE MEAN NUMERICAL VALUE\n",
    "\n",
    "  # FOR NON NUMERICAL COLUMNS, USE THE KEYWORD 'UNKNOWN' FOR NAN VALUES\n",
    "  for col in df.select_dtypes(exclude=np.number).columns:\n",
    "    df[col].fillna('Unknown', inplace=True)\n",
    "\n",
    "  # DROP NON-SALVAGABLE NAN VALUES\n",
    "  df.dropna(inplace=True)\n",
    "\n",
    "  dfs[year] = df  # STORE THE DATAFRAMES ACCORDINGLY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4CEY7y9-UIUj"
   },
   "source": [
    "Διαχωρίσαμε τα δεδομένα σε df_2019 και df_2023 για μελλοντική χρήση. Για ορισμένα ερωτήματα, ορίσαμε το df_unique_XXXX το οποίο παίρνει την πιο πρόσφατη εμφάνιση (κατά μήνα) με μοναδικό αναγνωριστικό, απορρίπτοντας όλα τα άλλα αντίγραφα. Επομένως, δεν έχουμε επαναλαμβανόμενες καταχωρήσεις εκεί που δεν χρειάζονται. Χρησιμοποιούμε το αντίστοιχο σύνολο δεδομένων ανάλογα με τις περιστάσεις."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6051,
     "status": "aborted",
     "timestamp": 1755178526059,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "pC8f4CfVUMXi"
   },
   "outputs": [],
   "source": [
    "df_2019 = dfs['2019']\n",
    "df_2023 = dfs['2023'] # WE DEFINE EACH DATASET FOR FUTURE USE WITHIN THE QUERIES\n",
    "\n",
    "df_unique_2019 = df_2019[df_2019['Month'] == 'april'].drop_duplicates(subset=['id'])\n",
    "df_unique_2023 = df_2023[df_2023['Month'] == 'september'].drop_duplicates(subset=['id']) # DENOTE UNIQUE VERSIONS OF THE DATASETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Fo34dTuDomo"
   },
   "source": [
    "**1.1** Ποιός είναι ο πιο συχνός τύπος room_type για τα δεδομένα σας;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6051,
     "status": "aborted",
     "timestamp": 1755178526060,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "_CjJr3NeDzic"
   },
   "outputs": [],
   "source": [
    "most_frequent_room_type_2019 = df_unique_2019['room_type'].mode()[0]\n",
    "print(f\"The most frequent room_type for 2019 is: {most_frequent_room_type_2019}\")\n",
    "\n",
    "most_frequent_room_type_2023 = df_unique_2023['room_type'].mode()[0]\n",
    "print(f\"The most frequent room_type for 2023 is: {most_frequent_room_type_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_-CoXJuVkB8"
   },
   "source": [
    "**1.2** Φτιάξτε γράφημα ή γραφήματα που δείχνουν την πορεία των τιμών για το διάστημα των 3 μηνών.  \n",
    "* Αποφασίσαμε να δημιουργήσουμε δύο διαφορετικά γραφήματα για να αποφύγουμε προβλήματα με τις τιμές NaN και τη λογική απεικόνισης. Χρησιμοποιούμε επίσης το μέσο όρο της τιμής για κάθε μήνα για τα γραφήματα.\n",
    "*Για αυτό το ερώτημα, χρειαζόμαστε μηνιαία δεδομένα, επομένως δεν χρησιμοποιούμε τα μοναδικά σύνολα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6051,
     "status": "aborted",
     "timestamp": 1755178526061,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "sS5qblJ4Vqiq"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# WE REMOVE THE $ SYMBOL SO WE CAN TAKE THE VALUES AS NUMERALS (float)\n",
    "df_2019['price'] = df_2019['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "df_2023['price'] = df_2023['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)\n",
    "\n",
    "# WE GROUP BY MONTH AND GET THE MEAN OF THE PRICES (FOR EACH MONTH ENTRY)\n",
    "df_2019_grouped = df_2019.groupby('Month')['price'].mean()\n",
    "df_2023_grouped = df_2023.groupby('Month')['price'].mean()\n",
    "\n",
    "# REORDER THE INDEX FOR EACH YEAR\n",
    "df_2019_grouped = df_2019_grouped.reindex(['febrouary', 'march', 'april'])\n",
    "df_2023_grouped = df_2023_grouped.reindex(['march', 'june', 'september'])\n",
    "\n",
    "# PLOT CREATIONS\n",
    "\n",
    "# 2019\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_2019_grouped.plot(label='2019')\n",
    "plt.title('Price Trend Over Specific Months in 2019')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Price')\n",
    "plt.legend()\n",
    "plt.xticks(range(len(df_2019_grouped)), df_2019_grouped.index)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\")\n",
    "# 2023\n",
    "plt.figure(figsize=(10, 6))\n",
    "df_2023_grouped.plot(label='2023')\n",
    "plt.title('Price Trend Over Specific Months in 2023')\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Average Price')\n",
    "plt.legend()\n",
    "plt.xticks(range(len(df_2023_grouped)), df_2023_grouped.index)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oyHZ-sstjSz4"
   },
   "source": [
    "**1.3** Ποιές είναι οι 5 πρώτες γειτονιές με τις περισσότερες κριτικές;\n",
    "* Εδώ εκπληρώσαμε την απαιτούμενη λειτουργία, αλλά προσθέσαμε επίσης έναν έλεγχο για την αφαίρεση του \"Unknown\", το οποίο τοποθετήσαμε για να συμπληρώσουμε τιμές NaN κατά την επεξεργασία του συνόλου δεδομένων μας (2023). Εν ολίγοις, δημιουργήσαμε μια άλλη έκδοση του συνόλου δεδομένων του 2023, η οποία αγνοεί τις εγγραφές με άγνωστη τοποθεσία."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6052,
     "status": "aborted",
     "timestamp": 1755178526062,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "eG9yl8fEjRlx"
   },
   "outputs": [],
   "source": [
    "df_unique_2019_noU = df_unique_2019[df_unique_2019['neighbourhood'] != 'Unknown'] # EDIT THE SET TO FILTER OUR UNKNOWN NEIGHBORHOODS\n",
    "df_unique_2023_noU = df_unique_2023[df_unique_2023['neighbourhood'] != 'Unknown'] # EDIT THE SET TO FILTER OUR UNKNOWN NEIGHBORHOODS\n",
    "\n",
    "top_5_neighborhoods_2019 = df_unique_2019_noU.groupby('neighbourhood')['number_of_reviews'].sum().nlargest(5) # GET THE 5 LARGEST SUM OF REVIEWS FOR THE SPECIFIED YEAR\n",
    "print(\"Top 5 neighborhoods with the most reviews in 2019:\")\n",
    "print(top_5_neighborhoods_2019)\n",
    "\n",
    "# REPEAT FOR 2023\n",
    "top_5_neighborhoods_2023 = df_unique_2023_noU.groupby('neighbourhood')['number_of_reviews'].sum().nlargest(5)\n",
    "print(\"\\nTop 5 neighborhoods with the most reviews in 2023:\")\n",
    "print(top_5_neighborhoods_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RtU20Fthm_I6"
   },
   "source": [
    "**1.4** Ποιά είναι η γειτονιά με τις περισσότερες καταχωρήσεις ακινήτων;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6052,
     "status": "aborted",
     "timestamp": 1755178526063,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "V4Yfob5Pm-jz"
   },
   "outputs": [],
   "source": [
    "top_neighborhood_2019 = df_unique_2019['neighbourhood'].value_counts().idxmax()\n",
    "top_neighborhood_2023 = df_unique_2023['neighbourhood'].value_counts().idxmax()\n",
    "\n",
    "print(f\"The neighborhood with the most unique property listings in 2019 is: {top_neighborhood_2019}\")\n",
    "print(f\"The neighborhood with the most unique property listings in 2023 is: {top_neighborhood_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L-MBX4e0rTEQ"
   },
   "source": [
    "**1.5** Πόσες είναι οι καταχωρήσεις ανά γειτονιά και ανά μήνα;\n",
    "\n",
    "**Παρατήρηση:** Με βάση συζήτησης στο e-class αποφασίσαμε να κάνουμε το **1.5** σε μορφή ιστογράμματος για να καλύψουμε και το ερώτημα **1.6**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6052,
     "status": "aborted",
     "timestamp": 1755178526064,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "HHu8-o4arTRB"
   },
   "outputs": [],
   "source": [
    "# GROUP THE DATAFRAMES BY 'NEIGHBOURHOOD' AND 'MONTH', COUNT THE NUMBER OF ENTRIES FOR EACH GROUP, AND RESHAPE THE RESULT INTO A DATAFRAME\n",
    "entries_per_neighborhood_month_2019 = df_2019.groupby(['neighbourhood', 'Month']).size().unstack()\n",
    "entries_per_neighborhood_month_2023 = df_2023.groupby(['neighbourhood', 'Month']).size().unstack()\n",
    "\n",
    "# PLOT A HORIZONTAL BAR CHART FOR THE 2019 DATA\n",
    "entries_per_neighborhood_month_2019.plot(kind='barh', figsize=(13,15), edgecolor='white', linewidth=0.5)\n",
    "plt.title('Number of entries per neighborhood and per month in 2019')\n",
    "plt.ylabel('Number of entries')\n",
    "plt.grid(axis='x', linestyle='-', alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# PLOT A HORIZONTAL BAR CHART FOR THE 2023 DATA\n",
    "entries_per_neighborhood_month_2023.plot(kind='barh', figsize=(13,15), edgecolor='white', linewidth=0.5)\n",
    "plt.title('Number of entries per neighborhood and per month in 2023')\n",
    "plt.ylabel('Number of entries')\n",
    "plt.grid(axis='x', linestyle='-', alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UfGQi4sZt5r9"
   },
   "source": [
    "**1.6** Σχεδιάστε το ιστόγραμμα της μεταβλητής neighborhood\n",
    "* Για αυτό το ερώτημα, χρησιμοποιήσαμε τα μοναδικά σύνολα δεδομένων και επιλέξαμε να αποκλείσουμε τις καταχωρήσεις στο σύνολο 2023 με λιγότερες από 3 εμφανίσεις λόγω των πολλών μοναδικών ονομάτων γειτονιάς εντός του σύνολου.\n",
    "* **Με βάση τις συζητήσεις στο eclass, αυτό το ερώτημα δεν χρειάζεται να υλοποιηθεί. Εφόσον το έχουμε ήδη υλοποιήσει, απλά το βαλαμε σε σχόλιο.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6059,
     "status": "aborted",
     "timestamp": 1755178526071,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "CgQX2zV3uPKn"
   },
   "outputs": [],
   "source": [
    "# neighborhood_counts_2019 = df_unique_2019['neighbourhood'].value_counts() # WE USE THE UNIQUE DATASET\n",
    "\n",
    "# # PLOT THE HISTOGRAM FOR 2019\n",
    "# plt.figure(figsize=(10,6))\n",
    "# neighborhood_counts_2019.plot(kind='bar')\n",
    "# plt.title('Histogram of Neighborhood')\n",
    "# plt.xlabel('Neighbourhood')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n",
    "\n",
    "# # WE CHOSE TO EXCLUDE VALUES WITH LESS THAN 3 ENTRIES DUE TO THE FORMAT OF THE DATA\n",
    "# neighborhood_counts_2023 = neighborhood_counts_2023[neighborhood_counts_2023 > 2]\n",
    "\n",
    "# # 2023\n",
    "# plt.figure(figsize=(10,6))\n",
    "# neighborhood_counts_2023.plot(kind='bar')\n",
    "# plt.title('Histogram of Neighborhood')\n",
    "# plt.xlabel('Neighbourhood')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLyXYLZlwI1p"
   },
   "source": [
    "**1.7** Ποιος είναι ο πιο συχνός τύπος δωματίου (room_type) σε κάθε γειτονιά\n",
    "(neighborhood);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6060,
     "status": "aborted",
     "timestamp": 1755178526073,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "gungUbyWwNTP"
   },
   "outputs": [],
   "source": [
    "print(\"#############################################################\\n\\n 2019: \\n\\n############################################################# \\n\\n\")\n",
    "most_common_room_type_2019 = df_unique_2019.groupby('neighbourhood')['room_type'].agg(lambda x: x.value_counts().index[0])\n",
    "print(most_common_room_type_2019)\n",
    "\n",
    "print(\"\\n\\n#############################################################\\n\\n 2023: \\n\\n############################################################# \\n\\n\")\n",
    "most_common_room_type_2023 = df_unique_2023.groupby('neighbourhood')['room_type'].agg(lambda x: x.value_counts().index[0])\n",
    "print(most_common_room_type_2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Cfiv3Siwydn"
   },
   "source": [
    "**1.8** Ποιός είναι ο πιο ακριβός τύπος δωματίου;\n",
    "* Για αυτό το ερώτημα, δημιουργούμε νέα σύνολα δεδομένων για να έχουμε πιο ακριβή αποτελέσματα."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6061,
     "status": "aborted",
     "timestamp": 1755178526074,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "jsNj4-jGw8aY"
   },
   "outputs": [],
   "source": [
    "# WE USE A NEW TEMPORARY DATASET AND DROP DUPLICATES THAT AREN'T THE HIGHEST PRICE (OF THE DUPLICATE ENTRIES)\n",
    "df_2019_18 = df_2019.sort_values('price', ascending=False).drop_duplicates(subset=['id'])\n",
    "df_2023_18 = df_2023.sort_values('price', ascending=False).drop_duplicates(subset=['id'])\n",
    "\n",
    "# WE GROUP BY ROOM TYPE AND GET THE MEAN OF EACH TYPE\n",
    "mean_price_2019 = df_2019_18.groupby('room_type')['price'].mean()\n",
    "mean_price_2023 = df_2023_18.groupby('room_type')['price'].mean()\n",
    "\n",
    "# WE SELECT THE HIGHEST MEAN OF THE ROOM TYPES.\n",
    "most_expensive_room_type_2019 = mean_price_2019.idxmax()\n",
    "most_expensive_room_type_2023 = mean_price_2023.idxmax()\n",
    "\n",
    "print(f\"The most expensive room type in 2019 is {most_expensive_room_type_2019}\")\n",
    "print(f\"The most expensive room type in 2023 is {most_expensive_room_type_2023}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OkgWGONVybR5"
   },
   "source": [
    "**1.9** Χρησιμοποιήστε τη βιβλιοθήκη Folium Map με τις στήλες latitude/longitude και\n",
    "εμφανίστε σε ένα χάρτη για ένα μήνα της επιλογής σας τα ακίνητα και στα popup στον\n",
    "χάρτη επιλέξτε όποια άλλη πληροφορία θέλετε να εμφανίζεται για το ακίνητο (πχ\n",
    "bed_type, room_type, transit κτλ).\n",
    "* Για αυτό το ερώτημα, έπρεπε να χρησιμοποιήσουμε ένα plugin του folium (MarkerCluster), καθώς η εκτέλεση των χαρτών έσπαγε τον ιστότοπο λόγω του πλήθους των ακινήτων που προσθέτονταν στο χάρτη."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6059,
     "status": "aborted",
     "timestamp": 1755178526075,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "b5oTN_bMybuK"
   },
   "outputs": [],
   "source": [
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# 2019\n",
    "m = folium.Map(location=[df_unique_2019['latitude'].mean(), df_unique_2019['longitude'].mean()], zoom_start=13) # GET A CENTER POINT BASED ON ALL THE LISTINGS\n",
    "\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# LOOP TO ADD EACH PROPERTY TO THE MAP BASED ON THE PROVIDED LAT/LONG\n",
    "for idx, row in df_unique_2019.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"Room type: {row['room_type']}\" # WE CHOSE TO DISPLAY THE ROOM_TYPE\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# DISPLAY THE FIRST MAP\n",
    "print('##############################################################\\n\\n\\n 2019 \\n\\n\\n############################################################## \\n')\n",
    "display(m)\n",
    "\n",
    "# 2023\n",
    "m2 = folium.Map(location=[df_unique_2023['latitude'].mean(), df_unique_2023['longitude'].mean()], zoom_start=13) # GET A CENTER POINT BASED ON ALL THE LISTINGS\n",
    "\n",
    "marker_cluster2 = MarkerCluster().add_to(m2)\n",
    "\n",
    "# LOOP TO ADD EACH PROPERTY TO THE MAP BASED ON THE PROVIDED LAT/LONG\n",
    "for idx, row in df_unique_2023.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['latitude'], row['longitude']],\n",
    "        popup=f\"Room type: {row['room_type']}\" # WE CHOSE TO DISPLAY THE ROOM_TYPE\n",
    "    ).add_to(marker_cluster2)\n",
    "\n",
    "# 2023 MAP\n",
    "print('\\n##############################################################\\n\\n\\n 2023 \\n\\n\\n############################################################## \\n')\n",
    "display(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFnQSLwN4j4V"
   },
   "source": [
    "**1.10** Φτιάξτε διαφορετικά wordclouds με τα δεδομένα από τη στήλη neighbourhood,\n",
    "transit, description, last_review.\n",
    "* Για αυτό το ερώτημα, παραλείψαμε την κατηγορία διαμετακόμισης για το σύνολο δεδομένων του 2023, καθώς δεν υπάρχει.\n",
    "* Επίσης, για κάθε accomodation παίρνουμε μόνο την πιο πρόσφατη κριτική που υποβλήθηκε, για να ελαχιστοποιήσουμε τον όγκο των δεδομένων. (e-class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6058,
     "status": "aborted",
     "timestamp": 1755178526076,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "7VYxFCl_4o6Y"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "# FILE PATHS FOR THE MOST RECENT FILE FOR EACH YEAR\n",
    "file_path_2019_april = '/content/drive/MyDrive/data/2019/april/reviews.csv'\n",
    "file_path_2023_september = '/content/drive/MyDrive/data/2023/september/reviews.csv'\n",
    "\n",
    "dfN_2019_april = pd.read_csv(file_path_2019_april)\n",
    "dfN_2019_april['date'] = pd.to_datetime(dfN_2019_april['date'])  # CONVERT THE 'DATE' COLUMN TO DATETIME\n",
    "dfN_2019_april = dfN_2019_april.sort_values(['listing_id', 'date'])  # SORT THE DATAFRAME BY 'LISTINGID' AND 'DATE'\n",
    "dfN_2019_april = dfN_2019_april.drop_duplicates('listing_id', keep='last')  # DROP DUPLICATES, KEEPING ONLY THE LAST COMMENT FOR EACH 'LISTINGID'\n",
    "\n",
    "# READ AND PROCESS THE DATA FOR SEPTEMBER 2023\n",
    "dfN_2023_september = pd.read_csv(file_path_2023_september)\n",
    "dfN_2023_september['date'] = pd.to_datetime(dfN_2023_september['date'])  # CONVERT THE 'DATE' COLUMN TO DATETIME\n",
    "dfN_2023_september = dfN_2023_september.sort_values(['listing_id', 'date'])  # SORT THE DATAFRAME BY 'LISTINGID' AND 'DATE'\n",
    "dfN_2023_september = dfN_2023_september.drop_duplicates('listing_id', keep='last')  # DROP DUPLICATES, KEEPING ONLY THE LAST COMMENT FOR EACH 'LISTINGID'\n",
    "\n",
    "text_2019 = dfN_2019_april['comments'].dropna().astype(str).str.cat(sep=' ')\n",
    "text_2023 = dfN_2023_september['comments'].dropna().astype(str).str.cat(sep=' ')\n",
    "\n",
    "# -------------------------\n",
    "\n",
    "# DEFINE THE DATA FOR EACH YEAR\n",
    "data = {'2019': df_unique_2019_noU, '2023': df_unique_2023_noU}\n",
    "\n",
    "# DEFINE THE COLUMNS YOU'RE INTERESTED IN\n",
    "columns = ['neighbourhood', 'description']\n",
    "\n",
    "# ITERATE OVER THE YEARS\n",
    "for year, df in data.items():\n",
    "    # ITERATE OVER THE COLUMNS\n",
    "    for column in columns:\n",
    "        # CONCATENATE ALL VALUES IN THE COLUMN INTO A SINGLE STRING\n",
    "        text = df[column].dropna().astype(str).str.cat(sep=' ')\n",
    "\n",
    "        # GENERATE A WORD CLOUD\n",
    "        wordcloud = WordCloud(background_color='white').generate(text)\n",
    "\n",
    "        # PLOT THE WORD CLOUD\n",
    "        plt.figure(figsize=(15, 15))\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Word Cloud for {column} - {year}')\n",
    "        plt.show()\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "# GENERATE A WORD CLOUD FOR THE 'TRANSIT' COLUMN IN THE 2019 DATAFRAME\n",
    "text = df_unique_2019['transit'].dropna().astype(str).str.cat(sep=' ')\n",
    "wordcloud = WordCloud(background_color='white').generate(text)\n",
    "\n",
    "# PLOT THE WORD CLOUD FOR THE 'TRANSIT' COLUMN\n",
    "plt.figure(figsize=(15, 15))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud for Transit - 2019')\n",
    "plt.show()\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# DEFINE THE DATA FOR EACH YEAR\n",
    "dataN = {'2019': dfN_2019_april, '2023': dfN_2023_september}\n",
    "\n",
    "# ITERATE OVER THE YEARS\n",
    "for year, df in dataN.items():\n",
    "    # CONCATENATE ALL VALUES IN THE 'COMMENTS' COLUMN INTO A SINGLE STRING\n",
    "    text = df['comments'].dropna().astype(str).str.cat(sep=' ')\n",
    "\n",
    "    # GENERATE A WORD CLOUD\n",
    "    wordcloud = WordCloud(background_color='white').generate(text)\n",
    "\n",
    "    # PLOT THE WORD CLOUD\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f'Word Cloud for Comments - {year}')\n",
    "    plt.show()\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVJjyvmOG8kP"
   },
   "source": [
    "**1.11** Στο ερώτημα αυτό θα αξιοποιήσουμε τη στήλη amenities. Στην συνέχεια\n",
    "και αφού έχετε απλοποιήσει αυτήν τη στήλη κάντε ένα ιστόγραμμα το οποίο θα\n",
    "κατανέμονται οι νέες τιμές.\n",
    "* Για αυτό το ερώτημα, παίρνουμε τη στήλη amenities και χωρίζουμε τα strings σε ξεχωριστα amenities. Στη συνέχεια χρησιμοποιήσαμε κώδικα για να εκτυπώσουμε μη διπλές καταχωρήσεις στη στήλη amenities και τις κατηγοριοποιήσαμε στις παρεχόμενες κατηγορίες (προσθέτοντας δύο δικές μας). Φιλτράραμε επίσης τα περιττά κενά για καλύτερη οργάνωση και αποφυγή σφαλμάτων. Τέλος, ισοπεδώσαμε τις κατηγορίες για να τις χρησιμοποιήσουμε για τη γραφική παράσταση και σχεδιάσαμε το ζητούμενο γράφημα.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6058,
     "status": "aborted",
     "timestamp": 1755178526077,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "0EWXcxWhIlSA"
   },
   "outputs": [],
   "source": [
    "# DEFINE THE AMENITIES INTO THE SPECIFIED CATEGORIES\n",
    "categories = {\n",
    "    'kitchen': ['Kitchen','Breakfast', 'Cooking basics', 'BBQ grill', 'Oven', 'Coffee maker','Dishes and silverware','Dishwasher','Refrigerator','Microwave', 'Gas oven', 'Children’s dinnerware', 'Kitchenette', 'Double oven', 'Full kitchen', 'Espresso machine', 'Steam oven', 'Hot water kettle', 'Convection oven', 'Mini fridge', 'Wine cooler', 'Breakfast table', 'Mudroom', 'Warming drawer'],\n",
    "    'bathroom': ['Hot water', 'Hair dryer','Essentials','Shampoo','Bathtub', 'Accessible-height toilet', 'Private bathroom', 'Bath towel', 'Bathtub with bath chair', 'En suite bathroom', 'Toilet paper', 'Bathroom essentials', 'Rain shower', 'Roll-in shower', 'Jetted tub', 'Walk-in shower', 'Heat lamps', 'Bidet', 'Body soap', 'Alfresco bathtub', 'Soaking tub', ' toilet', 'Shower chair', 'Stand alone steam shower'],\n",
    "    'accesibility': ['Wide doorway','Well-lit path to entrance','Step-free access','Elevator','Wide hallway clearance','Single level home', 'Flat path to front door', 'Ground floor access', 'Wide clearance to bed', 'Wide clearance to shower', 'Wide entryway', 'Disabled parking spot', 'Wheelchair accessible', 'Accessible-height bed', 'Fixed grab bars for toilet', 'Fixed grab bars for shower', 'Electric profiling bed'],\n",
    "    'Electricity_and_Technology': ['TV', 'Cable TV', 'Internet', 'Wifi','Air conditioning', 'Keypad', 'Amazon Echo', 'Smart lock', 'Game console', 'High-resolution computer monitor', 'Printer', 'Projector and screen', 'Smart TV', 'HBO GO', 'Netflix', 'DVD player', 'Central air conditioning', 'Ethernet connection', 'Pocket wifi', 'EV charger'],\n",
    "    'facilities': ['Washer', 'Dryer', 'Elevator','Iron','Stove','Patio or balcony','Heating','Private entrance','Room-darkening shades','Garden or backyard','Free parking on premises','Indoor fireplace', 'Freezer', 'Beachfront', 'Sun loungers', 'Fire pit', 'Private hot tub', 'Sauna', 'Shared gym', 'Terrace', 'Hot tub', 'Pool', 'Lake access', 'Private pool', 'Balcony', 'Ski-in/Ski-out', 'Ceiling fan', 'Outdoor parking', 'Heated floors', 'Heated towel rack', 'Touchless faucets', 'Standing valet', 'Outdoor seating', 'Waterfront', 'Washer / Dryer', 'Fireplace guards', 'Beach view'],\n",
    "    'kids_friendly': ['Family/kid friendly','Crib', 'Babysitter recommendations', 'Children’s books and toys', 'Changing table', 'High chair', 'Table corner guards', 'Outlet covers', 'Baby monitor', 'Pack ’n Play/travel crib', 'Baby bath', 'Window guards', 'Murphy bed', 'Stair gates','Gym'],\n",
    "    'security': ['Fire extinguisher','First aid kit','Carbon monoxide detector','Smoke detector','Buzzer/wireless intercom','Lockbox', 'Lock on bedroom door', 'Safety card'],\n",
    "    'services': ['Long term stays allowed','Laptop friendly workspace','Extra pillows and blankets','Luggage dropoff allowed','24-hour check-in','Paid parking off premises','Host greets you','Free street parking','Self check-in', 'Cleaning before checkout', 'Building staff', 'Doorman', 'Fax machine'],\n",
    "    'miscellaneous':['Hangers','EssentialsBed linens','Smoking allowed', 'Pets live on this property', 'Sound system', 'Firm mattress', 'Paid parking on premises', 'Other pet(s)', 'Pets allowed', 'Air purifier', 'Bedroom comforts', 'Memory foam mattress', 'Suitable for events', 'Ironing Board', 'Exercise equipment', 'Handheld shower head', 'Hammock', 'Day bed', 'Cat(s)', 'Dog(s)', 'Private living room', 'Other', 'Mountain view', 'Formal dining area', 'Pillow-top mattress', 'Beach essentials']\n",
    "}\n",
    "\n",
    "#REDIFINE THE UNIQUE DATASETS FOR EASE OF USE\n",
    "df_unique_2019 = df_2019[df_2019['Month'] == 'april'].drop_duplicates(subset=['id'])\n",
    "df_unique_2023 = df_2023[df_2023['Month'] == 'september'].drop_duplicates(subset=['id'])\n",
    "\n",
    "# SPLIT THE STRING BY SEPARATING IT WHEN A , IS FOUND\n",
    "df_unique_2019['amenities'] = df_unique_2019['amenities'].str.split(',')\n",
    "\n",
    "# REMOVE LEADING AND TRAILING SPACES AND FILTER BASED ON THE 9 MAIN CATEGORIES\n",
    "df_unique_2019['categories'] = df_unique_2019['amenities'].apply(lambda amenities: [category for category, items in categories.items() if any(item.strip() in amenities for item in items)])\n",
    "\n",
    "# FLATTEN THE LIST OF CATEGORIES INTO A SINGLE SERIES USING EXPLODE\n",
    "categories_series = df_unique_2019['categories'].explode()\n",
    "\n",
    "# PLOTTING THE HISTOGRAM\n",
    "categories_series.value_counts().plot(kind='bar')\n",
    "plt.title('HISTOGRAM OF AMENITY CATEGORIES 2019')\n",
    "plt.xlabel('CATEGORY')\n",
    "plt.ylabel('FREQUENCY')\n",
    "plt.show()\n",
    "\n",
    "#2023\n",
    "print(\"\\n\\n\")\n",
    "import ast\n",
    "\n",
    "# 2023\n",
    "print('##############################################################\\n\\n\\n 2023 \\n\\n\\n############################################################## \\n')\n",
    "df_unique_2023['amenities'] = df_unique_2023['amenities'].apply(ast.literal_eval) # WE USE AST TO CONVERT THE STRING ENCLOSED IN [] INTO AN ACTUAL LIST, AS WE CANNOT ITERATE IT OTHERWISE.\n",
    "df_unique_2023['categories'] = df_unique_2023['amenities'].apply(lambda amenities: [category for category, items in categories.items() if any(item.strip() in [amenity.strip() for amenity in amenities] for item in items)])\n",
    "categories_series2 = df_unique_2023['categories'].explode()\n",
    "\n",
    "# CHECK IF ITS EMPTY BEFORE PLOTTING TO AVOID ERRORS\n",
    "\n",
    "categories_series2.value_counts().plot(kind='bar')\n",
    "plt.title('HISTOGRAM OF AMENITY CATEGORIES 2023')\n",
    "plt.xlabel('CATEGORY')\n",
    "plt.ylabel('FREQUENCY')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybdOVhvgUNXp"
   },
   "source": [
    "**1.12** Υπολογίστε αρχικά την μέση τιμή ανα γειτονιά (θα χρησιμοποιηθεί η στήλη price,\n",
    "ενώ για να μπορούμε να συγκρίνουμε όμοια πράγματα κρατήστε μόνο τα δωμάτια που\n",
    "επιτρέπουν φιλοξενία δύο ατόμων). Δείξτε σε ένα γράφημα τις γειτονιές ταξινομημένες\n",
    "ανάλογα με την μέση τιμή τους. Στην συνέχεια κατατάξτε τις γειτονιές σε 3 ομάδες (πολύ\n",
    "ακριβές, μέτριες, οικονομικές) ανάλογα με την μέση τιμή των δωματίων.\n",
    "* Για αυτό το ερώτημα, υπολογίζουμε τον μέσο όρο για κάθε γειτονιά χωρίς διπλές εγγραφές. Στη συνέχεια ορίζουμε τις ζητούμενες κατηγορίες και συγχωνεύουμε τις απαιτούμενες στήλες, έπειτα τις ταξινομούμε και τέλος εκτυπώνουμε το γράφημα με κωδικοποίηση χρώματος.\n",
    "\n",
    "*   Για το έτος 2023, έχουμε δεδομένα από 2 λιγότερες γειτονιές αυτό οφείλεται στο γεγονός πως εκείνο το έτος και μήνα δεν υπήρχε κάποιο airbnb για 2 άτομα.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6058,
     "status": "aborted",
     "timestamp": 1755178526078,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "nAzXKz9A5k-V"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 2019\n",
    "# CALCULATE AVG PRICES PER NEIGHBOURHOOD\n",
    "df_two_persons = df_unique_2019[df_unique_2019['accommodates'] == 2].copy() # MAKE NEW DF COPY THAT ONLY CONTAINS ROOMS WITH 2 ACCOMMODATES\n",
    "df_two_persons['price'] = df_two_persons['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)  # REMOVE THE $ SYMBOL AND TURN THEM TO FLOAT\n",
    "average_price = df_two_persons.groupby('neighbourhood')['price'].mean().rename('average_price') # CALCULATE THE AVERAGE PRICE\n",
    "\n",
    "# DEFINE PRICE CATEGORIES\n",
    "bins = [0, average_price.quantile(0.33), average_price.quantile(0.66), average_price.max()] # PRICE BOUNDARIES BASED ON THE QUANTILES OF THE AVG PRICE\n",
    "labels = ['Economical', 'Moderate', 'Expensive']  # THE PRICE CATEGORIES\n",
    "neighbourhood_category = pd.cut(average_price, bins=bins, labels=labels)  # CREATE A NEW COLUMN 'NEIGHBOURHOOD_CATEGORY'\n",
    "\n",
    "# MERGE NEIGHBRHOODS, AVG PRICES & CATEGORIES\n",
    "neighbourhood_prices = pd.DataFrame(average_price).merge(neighbourhood_category.rename('neighbourhood_category'), left_index=True, right_index=True)\n",
    "neighbourhood_prices = neighbourhood_prices.sort_values(by='average_price') # SORT BY THE AVERAGE_PRICE\n",
    "# display(neighbourhood_prices)\n",
    "print(\"Number of rows in neighbourhood_prices: \", len(neighbourhood_prices))\n",
    "color_map = {'Economical': 'green', 'Moderate': 'yellow', 'Expensive': 'red'} # CREATE A COLOR MAP FOR THE PRICE CATEGORIES\n",
    "\n",
    "# PLOT THE GRAPH\n",
    "plt.figure(figsize=(13,8))\n",
    "for category in labels:\n",
    "    plt.bar(neighbourhood_prices[neighbourhood_prices['neighbourhood_category'] == category].index, # FET ALL NEIGHBOURHOODS OF THE CATEGORY\n",
    "            neighbourhood_prices[neighbourhood_prices['neighbourhood_category'] == category]['average_price'], # AVERAGE PRICES\n",
    "            color=color_map[category])  # COLOR BASED ON CATEGORY\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2023\n",
    "# CALCULATE AVG PRICES PER NEIGHBOURHOOD\n",
    "df_two_persons = df_unique_2023[df_unique_2023['accommodates'] == 2].copy() # MAKE NEW DF COPY THAT ONLY CONTAINS ROOMS WITH 2 ACCOMMODATES\n",
    "df_two_persons['price'] = df_two_persons['price'].replace({'\\$': '', ',': ''}, regex=True).astype(float)  # REMOVE THE $ SYMBOL AND TURN THEM TO FLOAT\n",
    "average_price = df_two_persons.groupby('neighbourhood')['price'].mean().rename('average_price') # CALCULATE THE AVERAGE PRICE\n",
    "\n",
    "# DEFINE PRICE CATEGORIES\n",
    "bins = [0, average_price.quantile(0.33), average_price.quantile(0.66), average_price.max()] # PRICE BOUNDARIES BASED ON THE QUANTILES OF THE AVG PRICE\n",
    "labels = ['Economical', 'Moderate', 'Expensive']  # THE PRICE CATEGORIES\n",
    "neighbourhood_category = pd.cut(average_price, bins=bins, labels=labels)  # CREATE A NEW COLUMN 'NEIGHBOURHOOD_CATEGORY'\n",
    "\n",
    "# MERGE NEIGHBRHOODS, AVG PRICES & CATEGORIES\n",
    "neighbourhood_prices = pd.DataFrame(average_price).merge(neighbourhood_category.rename('neighbourhood_category'), left_index=True, right_index=True)\n",
    "neighbourhood_prices = neighbourhood_prices.sort_values(by='average_price') # SORT BY THE AVERAGE_PRICE\n",
    "\n",
    "color_map = {'Economical': 'green', 'Moderate': 'yellow', 'Expensive': 'red'} # CREATE A COLOR MAP FOR THE PRICE CATEGORIES\n",
    "\n",
    "# display(neighbourhood_prices)\n",
    "print(\"Number of rows in neighbourhood_prices: \", len(neighbourhood_prices))\n",
    "# PLOT THE GRAPH\n",
    "plt.figure(figsize=(13,8))\n",
    "for category in labels:\n",
    "    plt.bar(neighbourhood_prices[neighbourhood_prices['neighbourhood_category'] == category].index, # GET ALL NEIGHBOURHOODS OF THE CATEGORY\n",
    "            neighbourhood_prices[neighbourhood_prices['neighbourhood_category'] == category]['average_price'], # AVERAGE PRICES\n",
    "            color=color_map[category])  # COLOR BASED ON CATEGORY\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaHD59SHdtuu"
   },
   "source": [
    "**1.13** Ποιά άλλη πληροφορία θα μπορούσατε να εξάγετε από τα δεδομένα που σας\n",
    "δίνονται; Σκεφτείτε 3 επιπλέον ερωτήσεις για την περιοχή της Αθήνας και εμφανίστε τα\n",
    "αποτελέσματα (μπορείτε και να συνδυάσετε όσες στήλες θέλετε από οποιαδήποτε\n",
    "χρονιά).\n",
    "* Ποιο είναι το λιγότερο διαθέσιμο \"room_type\" με βάση την 365_availability;\n",
    "* Ποιος είναι ο πιο συνηθισμένος ελάχιστος αριθμός διανυκτερεύσεων που απαιτείται για καταχωρήσεις στην Αθήνα;\n",
    "* Ποιος είναι ο μέσος αριθμός ατόμων που μπορεί να φιλοξενήσει μια καταχώριση στην Αθήνα;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6057,
     "status": "aborted",
     "timestamp": 1755178526078,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "mlv7vTHlmSR7"
   },
   "outputs": [],
   "source": [
    "# 2019\n",
    "# 1\n",
    "least_available_room_type_2019 = df_unique_2019.groupby('room_type')['availability_365'].mean().idxmin()\n",
    "print(f\"The least available room type in 2019 is: {least_available_room_type_2019}\")\n",
    "\n",
    "# 2\n",
    "most_common_minimum_nights_2019 = df_unique_2019['minimum_nights'].mode().values[0]\n",
    "print(f\"The most common minimum number of nights in 2019 is: {most_common_minimum_nights_2019}\")\n",
    "\n",
    "# 3\n",
    "average_accommodates_2019 = df_unique_2019['accommodates'].mean()\n",
    "print(f\"The average number of people a listing can accommodate in 2019 is: {average_accommodates_2019:.2f}\")\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# 2023\n",
    "# 1\n",
    "least_available_room_type_2023 = df_unique_2023.groupby('room_type')['availability_365'].mean().idxmin()\n",
    "print(f\"The least available room type in 2023 is: {least_available_room_type_2023}\")\n",
    "\n",
    "# 2\n",
    "most_common_minimum_nights_2023 = df_unique_2023['minimum_nights'].mode().values[0]\n",
    "print(f\"The most common minimum number of nights in 2023 is: {most_common_minimum_nights_2023}\")\n",
    "\n",
    "# 3\n",
    "average_accommodates_2023 = df_unique_2023['accommodates'].mean()\n",
    "print(f\"The average number of people a listing can accommodate in 2023 is: {average_accommodates_2023:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rebYNJLwi_wO"
   },
   "source": [
    "**1.14**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6058,
     "status": "aborted",
     "timestamp": 1755178526079,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "VCXl5zUGjPQf"
   },
   "outputs": [],
   "source": [
    "#REDEFINE THE UNIQUE DATASETS\n",
    "df_unique_2019 = df_2019[df_2019['Month'] == 'april'].drop_duplicates(subset=['id'])\n",
    "df_unique_2023 = df_2023[df_2023['Month'] == 'september'].drop_duplicates(subset=['id'])\n",
    "\n",
    "#2019\n",
    "# SUM THE LISTINGS ON THE UNIQUE DATASET BY EACH HOST ID\n",
    "host_listings = df_unique_2019.groupby('host_id').size()\n",
    "\n",
    "# USE HEAD(10) TO LIST THE TOP 10\n",
    "top_10_hosts = host_listings.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 hosts with the most accomodations for 2019\\n\")\n",
    "print(top_10_hosts)\n",
    "print(\"\\n\")\n",
    "\n",
    "#2023\n",
    "# SUM THE LISTINGS ON THE UNIQUE DATASET BY EACH HOST ID\n",
    "host_listings = df_unique_2023.groupby('host_id').size()\n",
    "\n",
    "# USE HEAD(10) TO LIST THE TOP 10\n",
    "top_10_hosts = host_listings.sort_values(ascending=False).head(10)\n",
    "\n",
    "print(\"Top 10 hosts with the most accomodations for 2023\\n\")\n",
    "print(top_10_hosts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vww4IpPspK4b"
   },
   "source": [
    "**1.15**\n",
    "\n",
    "Από τα παραπάνω ερωτήματα μπορούμε να βγάλουμε διάφορα συμπεράσματα για τις βραχύχρονες μισθώσεις στην Αθήνα.\n",
    "\n",
    "* Και τις δύο χρονίες παρατηρούμε από το γράφημα του ερωτήματος **1.2** πως οι τιμές των καταλυμάτων είναι χαμηλότερες την εποχή της άνοιξης, κάτι που είναι πολύ φυσιολογικό αφού η εποχή αυτή θεωρείται εκτός σεζόν.\n",
    "\n",
    "* Από τα ερωτήματα 1.3 - 1.6 & 1.9 παρατηρούμε πως οι πιο *ενεργές* περιοχές είναι αυτές που βρίσκονται κοντά στο κέντρο. Αυτό το καταλαβαίνουμε από το μεγάλο πλήθος κριτικών που έχουν τα καταλύματα σε αυτές τις περιοχές καθώς και από το μεγάλο αριθμό καταχωρημένων airbnb που θα βρούμε σε αυτές τις περιοχές όπως παρατηρούμε από τις κατανομημένες λίστες που έχουμε φτιάξει (1.3), τα ιστογραφήματα (1.5) αλλά ακόμα και από τη πυκνότητα που έχουν οι χάρτες μας σε αυτές τις περιοχές (1.9). Τέλος να σημειωθεί πως η πιο δημοφιλή από αυτές τις περιοχές, η \"ΕΜΠΟΡΙΚΟ ΤΡΙΓΩΝΟ-ΠΛΑΚΑ\", από το 2019 στο 2023 κατάφερε να μεγαλώσει τη διαφορά που έχει στις καταχωρήσεις συγκριτικά με τις άλλες περιοχές, άρα καταλήγουμε στο συμπέρασμα πως η τάση των airbnb να αυξάνονται προς το κέντρο της πόλης δεν φαίνεται να σταματάει.\n",
    "\n",
    "* Ένα κοινό χαρακτηριστικό που έχουν και οι δύο χρονιές σε όλες τις περιοχές είναι πως νοικιάζονται κυρίως καταλύματα που προσφέρουν ολόκληρο διαμέρισμα και όχι απλά ένα δωμάτιο σε κάποιο ξενοδοχείο ή σπίτι (1.7). Αυτό εξηγεί κιόλας γιατί πολλά amenities έχουν να κάνουν με κατηγορίες όπως π.χ. η κουζίνα (1.11).\n",
    "\n",
    "* Από το ερώτημα **1.12** παρατηρούμε πως το 2023 υπάρχει σημαντική αύξηση στις τιμές των καταλυμάτων σε όλες τις κατηγορίες τιμών. Οι περισσότερες ακριβές περιοχές, συνεχίζουν να είναι ακριβές αν και δεν είναι με την ίδια ακριβώς σειρά στη κατάταξη.\n",
    "\n",
    "* Ο παρακάτω κώδικας απαντάει στην πρώτη ερώτηση που έχει τεθεί στην εκφώνηση."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaAvUtcWUvda"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6066,
     "status": "aborted",
     "timestamp": 1755178526088,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "Ga0jbBEfpJLT"
   },
   "outputs": [],
   "source": [
    "# REDEFINE THE UNIQUE DATASETS\n",
    "df_unique_2019 = df_2019[df_2019['Month'] == 'april'].drop_duplicates(subset=['id'])\n",
    "df_unique_2023 = df_2023[df_2023['Month'] == 'september'].drop_duplicates(subset=['id'])\n",
    "\n",
    "# Q1: ARE THERE MORE/DIFFERENT NEIGHBORHOODS BETWEEN THE TWO YEARS?\n",
    "print(\"Q1: Are there more/different neighborhoods between the two years?\\n\")\n",
    "\n",
    "num_neighbourhoods_2019 = df_unique_2019['neighbourhood'].nunique() # FILTER DATAFRAME FOR EACH YEAR AND COUNT UNIQUE NEIGHBORHOODS\n",
    "num_neighbourhoods_2023 = df_unique_2023['neighbourhood'].nunique()\n",
    "\n",
    "print(f\"Number of unique neighborhoods in 2019: {num_neighbourhoods_2019}\")\n",
    "print(f\"Number of unique neighborhoods in 2023: {num_neighbourhoods_2023}\")\n",
    "\n",
    "is_same_num = num_neighbourhoods_2019 == num_neighbourhoods_2023  # CHECK IF THE NUMBER OF NEIGHBORHOODS IS THE SAME\n",
    "print(f\"Did the number of neighborhoods change from 2019 to 2023? {is_same_num}\\n\")\n",
    "\n",
    "neighbourhoods_2019 = set(df_unique_2019['neighbourhood'])  # GET UNIQUE NEIGHBORHOODS FOR EACH YEAR\n",
    "neighbourhoods_2023 = set(df_unique_2023['neighbourhood'])\n",
    "\n",
    "are_same = neighbourhoods_2019 == neighbourhoods_2023 # CHECK IF THE NEIGHBORHOODS ARE THE SAME\n",
    "print(f\"Are the neighborhoods in 2019 the same as in 2023? {are_same}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3WhByvXuQ5s0"
   },
   "source": [
    "# **Ερώτημα 2ο: Recommendation System**\n",
    "Σε αυτό το ερώτημα θα χρειαστείτε τις στήλες : 'id', 'name', 'description'.\n",
    "Σκοπός είναι να εξάγετε χρήσιμη πληροφορία από αυτά τα δεδομένα και να\n",
    "προσπαθήσετε να φτιάξετε ένα πρόγραμμα το οποίο θα παράγει προτάσεις\n",
    "(recommendations) για την περιοχή της Αθήνας. Στο πρώτο ερώτημα έχετε ήδη φτιάξει\n",
    "τα wordclouds για τη στήλη description. Σε αυτό το ερώτημα αφαιρέστε τα stop words,\n",
    "πειραματιστείτε με τις παραμέτρους του wordcloud και εντοπίστε τις πιο\n",
    "χαρακτηριστικές λέξεις που χρησιμοποιεί ο επισκέπτης για την περιοχή της Αθήνας.\n",
    "Στη συνέχεια δημιουργήστε μία νέα στήλη που θα έχει την ένωση (concatenation) των\n",
    "στηλών name και description (fill NA with NULL).\n",
    "\n",
    "* [ECLASS] για αυτό το ερώτημα, πέρνουμε μόνο μία χρονία (2019)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vu5GoN8PUzRF"
   },
   "source": [
    "**2.1** Δημιουργήστε τον TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "πίνακα των unigrams και των bigrams για τη νέα στήλη (χρησιμοποιήστε την\n",
    "παράμετρο stop_word του TfidfVectorizer).\n",
    "\n",
    "<!-- Στο συγκεκριμένο ερώτημα αφαιρούμε τα διπλότυμα ids για να αποφύγουμε τη σύγκριση παρόμοιων περιγραφών και παίρνουμε μόνο ένα δείγμα των δεδομένων για τη καλύτερη διαχείριση των δεδομένων και τη γρηγορότερη επεξεργασία τους. -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6068,
     "status": "aborted",
     "timestamp": 1755178526090,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "deOkKYm1U38l"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# DROP DUPLICATES\n",
    "df_unique_2019 = df_2019[df_2019['Month'] == 'april'].drop_duplicates(subset=['id'])\n",
    "\n",
    "# ASSIGNMENT DATA HANDLING REQUESTS\n",
    "df_unique_2019['name'].fillna('NULL', inplace=True)\n",
    "df_unique_2019['description'].fillna('NULL', inplace=True)\n",
    "df_unique_2019['name_description'] = df_unique_2019['name'] + ' ' + df_unique_2019['description']\n",
    "\n",
    "# GET 5% OF THE DATA\n",
    "# df_2019_sample = df_unique_2019.sample(frac=0.80)\n",
    "\n",
    "# CREATE NEW VECTORIZER\n",
    "vectorizer_2019 = TfidfVectorizer(stop_words='english', ngram_range=(1, 2)) # ENGLISH = KNOWN DATASET OF COMMON WORDS IN ENGLISH\n",
    "\n",
    "# USE THE NEW COLUMN FOR THE VECTORIZER FOR 2019\n",
    "tfidf_matrix_2019 = vectorizer_2019.fit_transform(df_unique_2019['name_description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IrSI843sYdzI"
   },
   "source": [
    "**2.2** Cosine Similarity: Η μετρική αυτή υπολογίζει την ομοιότητα μεταξύ δύο\n",
    "διανυσμάτων x,y, χρησιμοποιώντας τη γωνία μεταξύ τους (όταν η γωνία είναι 0\n",
    "σημαίνει ότι τα x και y είναι ίσα , αν εξαιρέσουμε το μήκος τους). Διατρέξτε τον\n",
    "TF-IDF πίνακα και υπολογίστε το similarity καθενός ακινήτου με τα υπόλοιπα.\n",
    "\n",
    "Τις ομοιότητες κάθε ακινήτου με τα υπόλοιπα τις αποθηκεύουμε σε ένα dictionary όπου χρησιμοποιούμε ως κλειδί το id του ακινήτου αυτού. Τα ακίνητα αυτά είναι ταξινομημένα με βάση το σκορ ομοιότητας."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6093,
     "status": "aborted",
     "timestamp": 1755178526115,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "ePmwp1hTYdbi"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# CALCULATE COSINE SIMILARITY BETWEEN EACH ENTRY (CRASHES)\n",
    "similarity_2019 = cosine_similarity(tfidf_matrix_2019)\n",
    "\n",
    "# DICTIONARIES TO STORE THE TOP 100\n",
    "most_similar_2019 = {}\n",
    "\n",
    "# COMPARE THE RESULTS TO FIND THE TOP 100 FOR 2019\n",
    "for i in range(len(similarity_2019)):\n",
    "    similar_indices = np.argsort(similarity_2019[i])[::-1]\n",
    "    key = df_unique_2019.iloc[i]['id']  # GET THE ID OF THE ITEM\n",
    "    most_similar_2019[key] = df_unique_2019.iloc[similar_indices[1:101]]['id'].values  # EXCLUDE ITSELF FROM THE SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "laO3u5s3Z7f1"
   },
   "source": [
    "**2.3** Πρόβλεψη : Φτιάξτε μία συνάρτηση η οποία παίρνει σαν είσοδο ένα id και έναν\n",
    "ακέραιο αριθμό N, και επιστρέφει τα Ν πιο όμοια ακίνητα.\n",
    "\n",
    "\n",
    "*   Ελέγχουμε αν το ακίνητο υπάρχει στο δείγμα που έχουμε πάρει\n",
    "*   Παίρνουμε τα ακίνητα με τη μεγαλύτερη ομοιότητα για το ακίνητο που κάνουμε τη πρόβλεψη\n",
    "*   Εκτυπώνουμε τα αποτελέσματα (Το όνομα και τη περιγραφή τα βρίσκουμε με βάση το id και τη σκορ ομοιότητας με βάση το index)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6095,
     "status": "aborted",
     "timestamp": 1755178526117,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "yGJqMFBvZ79P"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def recommend(item_id, num): # FUNCTION DECLARATION num = N\n",
    "    # CHECK IF THE item_id EXISTS IN THE DATAFRAME\n",
    "    if item_id not in df_unique_2019['id'].values:\n",
    "        print(f\"No property found with ID {item_id}\")\n",
    "        return\n",
    "\n",
    "    # GET THE INDICES OF THE HIGHEST COSINE SIMILARITY PROPERTIES\n",
    "    similar_item_ids = most_similar_2019[item_id][:num]\n",
    "\n",
    "    # PRINT THE RECOMMENDATIONS IN THE REQUIRED FORMAT\n",
    "    print(f\"Recommending {num} listings similar to \\\"{df_unique_2019[df_unique_2019['id'] == item_id]['name'].values[0]}\\\"\")\n",
    "    print(\"---------------------------------------------------------\")\n",
    "    for similar_item_id in similar_item_ids:\n",
    "        print(f\"Recommended: {df_unique_2019[df_unique_2019['id'] == similar_item_id]['name'].values[0]}\")\n",
    "        print(f\"Description: {df_unique_2019[df_unique_2019['id'] == similar_item_id]['description'].values[0]}\")\n",
    "        print(f\"(score: {similarity_2019[df_unique_2019['id'].values.tolist().index(item_id)][df_unique_2019['id'].values.tolist().index(similar_item_id)]})\\n\")\n",
    "\n",
    "random_id = random.choice(df_unique_2019['id'].values)  # SELECT A RANDOM ITEM_ID\n",
    "print(random_id)\n",
    "recommend(random_id, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sqkr6ub6aRgr"
   },
   "source": [
    "**2.4** Λέξεις που εμφανίζονται συχνά μαζί με άλλες λέξεις (collocation).\n",
    "Χρησιμοποιήστε τον BigramCollocationFinder για να βρείτε 10 words που\n",
    "“τείνουν” να εμφανίζονται συχνά μαζί.\n",
    "\n",
    "*   Τη πρώτη φορά ο χρόνος εκτέλεσης είναι παραπάνω λόγω της εγκατάστασης της βιβλιοθήκης nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6100,
     "status": "aborted",
     "timestamp": 1755178526123,
     "user": {
      "displayName": "George Papaioannou",
      "userId": "09746213523201906573"
     },
     "user_tz": -180
    },
    "id": "6PeOATJAaUmT"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.metrics import BigramAssocMeasures\n",
    "\n",
    "# CONCATENATE ALL DESCRIPTIONS INTO A SINGLE STRING\n",
    "all_descriptions = ' '.join(df_unique_2019['description'])\n",
    "\n",
    "# TOKENIZE THE STRING INTO WORDS\n",
    "words = nltk.word_tokenize(all_descriptions)\n",
    "\n",
    "# CREATE A BigramCollocationFinder AND APPLY THE FREQUENCY FILTER\n",
    "bigram_finder = BigramCollocationFinder.from_words(words)\n",
    "bigram_finder.apply_freq_filter(3)\n",
    "\n",
    "# FIND THE TOP 10 BIGRAMS USING THE PMI MEASURE\n",
    "top_10_bigrams = bigram_finder.nbest(BigramAssocMeasures.pmi, 10)\n",
    "\n",
    "# PRINT THE TOP 10 BIGRAMS\n",
    "for bigram in top_10_bigrams:\n",
    "    print(' '.join(bigram))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
